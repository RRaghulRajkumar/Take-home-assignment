{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23373479-38a1-43d2-9d67-10321bff2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46766d18-b3ef-41a8-a2e4-bcc123c81014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting timedelta\n",
      "  Using cached timedelta-2020.12.3.tar.gz (1.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Building wheels for collected packages: timedelta\n",
      "  Building wheel for timedelta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for timedelta: filename=timedelta-2020.12.3-py3-none-any.whl size=1556 sha256=d5085747c1a719f3cf7f9834d95990a44deb6e68230c5fca804c95c8a348a0ab\n",
      "  Stored in directory: /Users/raghulrajkumar/Library/Caches/pip/wheels/6a/d4/2e/22908853a465dbeae5d67583a77bacaa0aba24288e7778f840\n",
      "Successfully built timedelta\n",
      "Installing collected packages: timedelta\n",
      "Successfully installed timedelta-2020.12.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fba9c8-d5c8-4826-8974-cc5d91c20e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet: Example 1 Ashby\n",
      "   Include or Exclude?  Start Date  End Date  Notes       date  \\\n",
      "0                  NaN         NaN       NaN    NaN 2022-06-15   \n",
      "1                  NaN         NaN       NaN    NaN 2022-06-16   \n",
      "2                  NaN         NaN       NaN    NaN 2022-07-31   \n",
      "3                  NaN         NaN       NaN    NaN 2022-08-31   \n",
      "4                  NaN         NaN       NaN    NaN 2022-09-30   \n",
      "\n",
      "   line_amount_usd    record_type  \\\n",
      "0          7580.00       purchase   \n",
      "1          7580.00    transaction   \n",
      "2           631.67  journal_entry   \n",
      "3           631.67  journal_entry   \n",
      "4           631.67  journal_entry   \n",
      "\n",
      "                                        account_name  \\\n",
      "0     Other Current Assets:Prepaids:Prepaid Expenses   \n",
      "1                                                NaN   \n",
      "2  General and Administrative Expenses:Profession...   \n",
      "3  General and Administrative Expenses:Profession...   \n",
      "4  General and Administrative Expenses:Profession...   \n",
      "\n",
      "                  account_type                 memo               memo_2  \\\n",
      "0          Other Current Asset  July 2021-June 2022  July 2021-June 2022   \n",
      "1  RECURRING_SOFTWARE_AND_SAAS                Ashby     ATS - Recruiting   \n",
      "2                      Expense                  NaN        Ashby 2022-07   \n",
      "3                      Expense                  NaN        Ashby 2022-07   \n",
      "4                      Expense                  NaN        Ashby 2022-09   \n",
      "\n",
      "  integration other_integration_list  \n",
      "0  quickbooks                    NaN  \n",
      "1        brex                     []  \n",
      "2  quickbooks                    NaN  \n",
      "3  quickbooks                    NaN  \n",
      "4  quickbooks                    NaN   \n",
      "\n",
      "Sheet: Example 2 Datadog\n",
      "   Include or Exclude?  Start Date  End Date  Notes       date  \\\n",
      "0                  NaN         NaN       NaN    NaN 2020-05-08   \n",
      "1                  NaN         NaN       NaN    NaN 2020-05-08   \n",
      "2                  NaN         NaN       NaN    NaN 2020-06-09   \n",
      "3                  NaN         NaN       NaN    NaN 2020-06-09   \n",
      "4                  NaN         NaN       NaN    NaN 2020-07-11   \n",
      "\n",
      "   line_amount_usd  record_type                       account_name  \\\n",
      "0           1829.0     purchase  General & Admin Software Expenses   \n",
      "1           1829.0  transaction                                NaN   \n",
      "2           6300.3     purchase  General & Admin Software Expenses   \n",
      "3           6300.3  transaction                                NaN   \n",
      "4           6456.6     purchase  General & Admin Software Expenses   \n",
      "\n",
      "                  account_type     memo memo_2 integration  \\\n",
      "0                      Expense      NaN    NaN  quickbooks   \n",
      "1  RECURRING_SOFTWARE_AND_SAAS  Datadog    NaN        brex   \n",
      "2                      Expense      NaN    NaN  quickbooks   \n",
      "3  RECURRING_SOFTWARE_AND_SAAS  Datadog    NaN        brex   \n",
      "4                      Expense      NaN    NaN  quickbooks   \n",
      "\n",
      "  other_integration_list  \n",
      "0               [\"brex\"]  \n",
      "1         [\"quickbooks\"]  \n",
      "2               [\"brex\"]  \n",
      "3         [\"quickbooks\"]  \n",
      "4               [\"brex\"]   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = \"./data/data.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load each sheet into a dictionary of DataFrames\n",
    "sheets = {sheet_name: xls.parse(sheet_name) for sheet_name in xls.sheet_names}\n",
    "\n",
    "# Check data structure\n",
    "for sheet_name, df in sheets.items():\n",
    "    print(f\"Sheet: {sheet_name}\")\n",
    "    print(df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70e1af7-e42d-4cb3-b361-8acf389f4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify and Exclude Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45c8ced-e0e7-4862-9b26-f74c8455e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    df['duplicate_flag'] = df.duplicated(subset=['date', 'line_amount_usd', 'memo'], keep=False)\n",
    "    \n",
    "    # Prioritize by integration: Bill.com > QuickBooks (QBO) > Brex\n",
    "    integration_priority = {'bill.com': 3, 'quickbooks': 2, 'brex': 1}\n",
    "    df['integration_score'] = df['integration'].map(integration_priority).fillna(0)\n",
    "\n",
    "    df = df.sort_values(by=['duplicate_flag', 'integration_score'], ascending=[False, False])\n",
    "    \n",
    "    # Keep only one record of each duplicate set\n",
    "    df = df.drop_duplicates(subset=['date', 'line_amount_usd', 'memo'], keep='first')\n",
    "    \n",
    "    return df.drop(columns=['duplicate_flag', 'integration_score'])\n",
    "\n",
    "# Apply to each sheet\n",
    "sheets = {name: remove_duplicates(df) for name, df in sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bc9863-16a8-4105-8408-90d59c9433b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exclude Journal Entries (Amortization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc9c316-b092-4370-88ed-183bc7d3a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_journal_entries(df):\n",
    "    df['Include/Exclude'] = df['record_type'].apply(lambda x: \"Exclude\" if x == \"journal_entry\" else \"Include\")\n",
    "    return df\n",
    "\n",
    "sheets = {name: exclude_journal_entries(df) for name, df in sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe4b387-6d23-4177-a0a2-194200d5da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Assign Start and End Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f36e5aab-0543-4e3c-837c-51d16a95bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def assign_dates(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['Include/Exclude'] == \"Include\":\n",
    "            memo = str(row['memo']) if pd.notna(row['memo']) else \"\"  # Ensure it's a string\n",
    "\n",
    "            if '-' in memo:  # Check if memo contains a date range\n",
    "                parts = memo.split('-')\n",
    "                try:\n",
    "                    df.at[index, 'Start Date'] = pd.to_datetime(parts[0].strip(), errors='coerce')\n",
    "                    df.at[index, 'End Date'] = pd.to_datetime(parts[1].strip(), errors='coerce')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing dates for row {index}: {e}\")\n",
    "                    df.at[index, 'Start Date'] = row['date']\n",
    "                    df.at[index, 'End Date'] = row['date'] + timedelta(days=30)\n",
    "\n",
    "            else:\n",
    "                # Default assumption: start from transaction date, assume 1-month service period\n",
    "                df.at[index, 'Start Date'] = row['date']\n",
    "                df.at[index, 'End Date'] = row['date'] + timedelta(days=30)\n",
    "        else:\n",
    "            df.at[index, 'Start Date'] = None\n",
    "            df.at[index, 'End Date'] = None\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "sheets = {name: assign_dates(df) for name, df in sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a8ebc3-3471-424a-9c40-cf2c18a75451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Justification for Inclusion/Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c7d9b8-cebe-4638-b7af-c375929945ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_notes(df):\n",
    "    df['Notes'] = df.apply(lambda row: \n",
    "        \"Excluded due to duplicate or amortization.\" if row['Include/Exclude'] == \"Exclude\" else \n",
    "        \"Included based on transaction details and inferred service period.\", axis=1)\n",
    "    return df\n",
    "\n",
    "sheets = {name: add_notes(df) for name, df in sheets.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8ac1a05-ad4a-4aa6-848d-781050784cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save the Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c41d27-6a8e-4e8a-a7e1-80deb909f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./data/Cleaned_Data_QA_Specialist.xlsx\"\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    for name, df in sheets.items():\n",
    "        df.to_excel(writer, sheet_name=name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37862ea3-4996-4e4c-bc7d-aa1a7bb5eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Completed. Saved as: Cleaned_Data_QA_Specialist_Final.xlsx\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a4c04-54cc-4446-96ed-abe9b0e6ee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
